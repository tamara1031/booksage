# BookSage Environment Configuration (Docker Environment)

# ==============================================================================
# 1. BookSage (Back-end: Orchestrator & Worker)
# ==============================================================================

# Address of the ML Worker gRPC service (uses container name in Docker)
SAGE_WORKER_ADDR=worker:50051

# Google Gemini API Key (Required unless SAGE_USE_LOCAL_ONLY_LLM=true)
SAGE_GEMINI_API_KEY=

# Toggle to skip cloud LLMs and use local Ollama exclusively
SAGE_USE_LOCAL_ONLY_LLM=true

# Worker specific settings
SAGE_WORKER_LISTEN_ADDR=[::]:50051
SAGE_WORKER_MAX_WORKERS=

# Timeout Settings (Seconds)
SAGE_DEFAULT_TIMEOUT_SEC=30
SAGE_EMBEDDING_TIMEOUT_SEC=5
SAGE_PARSER_TIMEOUT_SEC=60


# ==============================================================================
# 2. BookScout (Front-end: Web App)
# ==============================================================================

# API address for frontend to orchestrator communication
SCOUT_API_BASE_URL=http://api:8080/api/v1

# Book source type (opds)
SCOUT_BOOK_SOURCE_TYPE=opds

# OPDS Source Configuration
SCOUT_OPDS_BASE_URL=http://localhost:8000/api/v1/opds
SCOUT_OPDS_USERNAME=test
SCOUT_OPDS_PASSWORD=test

# General UI/App settings
SCOUT_PORT=8000
SCOUT_LOG_LEVEL=info

# Worker job settings
SCOUT_WORKER_SINCE_TIMESTAMP=0
SCOUT_WORKER_CONCURRENCY=5
SCOUT_WORKER_BATCH_SIZE=0

# File size limit (bytes, default: 50MB)
SCOUT_MAX_BOOK_SIZE_BYTES=52428800


# ==============================================================================
# 3. Common Infrastructure (Databases & LLM Server)
# ==============================================================================

# Neo4j authentication (format: username/password)
NEO4J_AUTH=neo4j/booksage_dev

# Ollama configuration for local LLM fallback
SAGE_OLLAMA_HOST=http://ollama:11434
SAGE_OLLAMA_MODEL=llama3

# Database configuration (Defaults for docker internal usage)
# SAGE_QDRANT_HOST=qdrant
# SAGE_NEO4J_URI=bolt://neo4j:7687
