# BookSage Environment Configuration (Docker Environment)

# ==============================================================================
# 1. BookSage (Back-end: Orchestrator & Worker)
# ==============================================================================

# Address of the ML Worker gRPC service (uses container name in Docker)
BS_WORKER_ADDR=worker:50051

# Google Gemini API Key (Required unless BS_USE_LOCAL_ONLY_LLM=true)
BS_GEMINI_API_KEY=

# Toggle to skip cloud LLMs and use local Ollama exclusively
BS_USE_LOCAL_ONLY_LLM=true

# Worker specific settings
BS_WORKER_LISTEN_ADDR=[::]:50051
BS_WORKER_MAX_WORKERS=

# Timeout Settings (Seconds)
BS_DEFAULT_TIMEOUT_SEC=30
BS_EMBEDDING_TIMEOUT_SEC=5
BS_PARSER_TIMEOUT_SEC=60


# ==============================================================================
# 2. BookScout (Front-end: Web App)
# ==============================================================================

# API address for frontend to orchestrator communication
BS_API_BASE_URL=http://api:8080/api/v1

# OPDS Source Configuration
BS_OPDS_BASE_URL=http://localhost:8000/api/v1/opds
BS_OPDS_USERNAME=test
BS_OPDS_PASSWORD=test

# General UI/App settings
BS_PORT=8000
BS_LOG_LEVEL=info


# ==============================================================================
# 3. Common Infrastructure (Databases & LLM Server)
# ==============================================================================

# Neo4j authentication (format: username/password)
NEO4J_AUTH=neo4j/booksage_dev

# Ollama configuration for local LLM fallback
BS_OLLAMA_HOST=http://ollama:11434
BS_OLLAMA_MODEL=llama3

# Database configuration (Defaults for docker internal usage)
# BS_QDRANT_HOST=qdrant
# BS_NEO4J_URI=bolt://neo4j:7687
