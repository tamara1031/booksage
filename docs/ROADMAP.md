# BookSage Development Roadmap & Technical Sync

---

## 1. Development Phases & Roadmap

### Current Assessment (As-Is)

Based on a thorough review of the actual codebase, the following **Implemented / Mock** statuses have been confirmed.

| Layer | Implemented âœ… | Mock/Stub ğŸŸ¡ |
|---|---|---|
| Infra & CI | Docker Compose, CI (lint/test), Makefile | â€” |
| gRPC Communication | Proto Definitions, Client Streaming (Parse), Unary (Embedding) | â€” |
| Go API | Server (REST+SSE +Middleware), Config, Embedding Batcher, LLM Router, Ingest Saga, Fusion Retriever (Dense+Graph), Agent/Generator (CoR+Self-RAG), Circuit Breaker, Graceful Shutdown | RAPTOR Engine, ColBERT Engine |
| Go DB Client | Qdrant Client (Search+Insert+Delete+PayloadIndex), Neo4j Client (Insert+Search+Delete) | â€” |
| Python Worker | gRPC Servicer, DocumentParser (Docling/PyMuPDF), EmbeddingGenerator | SelfRAGCritique, ColBERT, RAPTOR |
| DB Schema | Qdrant Collection (dense), Neo4j (Documentâ†’Chunk graph) | ColBERT/RAPTOR Collections |

---

### Phase 1: End-to-End Ingest MVP (Foundational)

> **Goal**: Ingest a single document and verify that data is correctly stored in Qdrant/Neo4j.

| Task | Component | Status |
|---|---|---|
| Worker: Split Docling parse results into Chunks â†’ gRPC Response | Python | âœ… |
| Go: Correctly construct Chunks/Nodes from gRPC Parse response | Go | âœ… |
| Go: Real Qdrant Client vector insertion (deterministic ID + PayloadIndex) | Go | âœ… |
| Go: Real Neo4j Client node/edge insertion (Documentâ†’Chunk graph) | Go | âœ… |
| E2E Test: Automated test for PDF ingest â†’ DB verification | Both | ğŸŸ¡ |

**Completion Criteria**: `make up-build` â†’ Upload PDF â†’ Data verified in Qdrant/Neo4j.

---

### Phase 2: Single-Engine Retrieval + Basic Q&A

> **Goal**: Answer questions using a single vector search engine.

| Task | Component | Status |
|---|---|---|
| Go Fusion: Connect Qdrant Dense Search | Go | âœ… |
| Worker: Query Embedding generation | Python | âœ… |
| Go Agent: Pass Context + Query to LLM for answer generation (RAG Prompt) | Go | âœ… |
| Server: Return real-time answers via SSE Streaming | Go | âœ… |
| Neo4j Cypher Query implementation (Graph Search / CONTAINS) | Go | âœ… |

**Completion Criteria**: Query `/api/v1/query` â†’ Qdrant search â†’ LLM generation â†’ SSE response.

---

### Phase 3: Multi-Engine Fusion + Self-RAG

> **Goal**: 3-engine parallel search + Intent Fusion + Self-RAG evaluation loop.

| Task | Component | Status |
|---|---|---|
| Go Fusion: Parallel connection of 3 engines (Graph/RAPTOR/ColBERT) | Go | âœ… |
| Python: ColBERT Late Interaction implementation | Python | âœ… |
| Python: RAPTOR Tree construction + Search | Python | âœ… |
| Go Agent: Self-RAG (Retrieval Critique â†’ Generation Critique) | Go | âœ… |
| Go Agent: Dual-level Retrieval (Specific & Abstract Extraction) | Go | âœ… |
| Intent-Driven Dynamic Fusion (Operator Pattern + Skyline Ranker) | Go | âœ… |

**Completion Criteria**: Complex query â†’ Intent classification â†’ Weighted Fusion â†’ Self-evaluation â†’ High-quality answer.

---

### Phase 4: Production Readiness & Scaling

> **Goal**: Observability, fault tolerance, and performance optimization.

| Task | Component | Status |
|---|---|---|
| Request ID Middleware + Structured Logging + Recovery | Go | âœ… |
| Circuit Breaker (Closed/Open/HalfOpen) | Go | âœ… |
| Health/Readiness Probes (/healthz, /readyz) | Go | âœ… |
| Graceful Shutdown (SIGTERM/SIGINT) | Go | âœ… |
| OpenTelemetry Tracing (correlation_id propagation) | Both | ğŸŸ¡ |
| GPU Memory Management & Model Warm-up | Python | ğŸŸ¡ |
| Kubernetes Manifests (HPA, Resource Limits) | Infra | ğŸŸ¡ |
| BookScout OPDS Scraper â†’ Ingest API Integration | Go | ğŸŸ¡ |

---

## 2. gRPC Interface Design

### Current Proto Definition (Implemented)

```mermaid
graph LR
    subgraph "Go API (Client)"
        A[Orchestrator]
    end
    subgraph "Python Worker (Server)"
        B[DocumentParser]
        C[EmbeddingGenerator]
    end
    A -->|"Parse(stream) â†’ Client Streaming"| B
    A -->|"GenerateEmbeddings(unary)"| C
```

| RPC | Direction | Streaming | Purpose |
|---|---|---|---|
| `Parse(stream ParseRequest) â†’ ParseResponse` | Goâ†’Python | **Client Streaming** | PDF/EPUB binary transfer (Bypass 4MB limit) |
| `GenerateEmbeddings(EmbeddingRequest) â†’ EmbeddingResponse` | Goâ†’Python | Unary | Text-to-Vector conversion |

### Proposed RPC Enhancements

| Candidate RPC | Streaming | Rationale |
|---|---|---|
| `AgenticGenerate(QueryRequest) â†’ stream AgenticEvent` | **Server Streaming** | Reduce TTFT for SSE responses. Stream reasoning traces, sources, and answer chunks. |
| `RetrieveFromWorker(RetrievalRequest) â†’ RetrievalResponse` | Unary | If ColBERT Late Interaction is executed on the Worker side. |
| `HealthCheck(Empty) â†’ HealthResponse` | Unary | Worker liveness / readiness probe. |

> [!IMPORTANT]
> **Server Streaming for Agentic**: When implementing Phase 2's `/api/v1/query` SSE, a **two-tier** approach is required: Goâ†’Frontend via HTTP SSE, and Goâ†’Python via gRPC Server Streaming.

---

## 3. Core Data Pipeline Flows

### 3.1 Ingestion Pipeline

```mermaid
sequenceDiagram
    participant User as User/BookScout
    participant API as Go API
    participant Worker as Python Worker
    participant Qdrant
    participant Neo4j
    participant SQLite

    User->>API: POST /api/v1/ingest (multipart)
    API->>API: SHA256 Calculation â†’ Duplicate Check
    API->>SQLite: CreateDocument + CreateSaga(Pending)

    rect rgb(40, 40, 80)
    Note over API,Worker: gRPC Client Streaming
    API->>Worker: ParseRequest{metadata} (1st msg)
    API->>Worker: ParseRequest{chunk_data} (2nd~N msg)
    Worker->>Worker: ETL via Docling/PyMuPDF
    Worker->>Worker: Layout-aware Chunking
    Worker-->>API: ParseResponse{documents[], metadata}
    end

    rect rgb(40, 80, 40)
    Note over API,Worker: gRPC Unary (Batched)
    API->>Worker: EmbeddingRequest{texts[], "dense"}
    Worker->>Worker: sentence-transformers encode
    Worker-->>API: EmbeddingResponse{DenseVector[]}
    end

    API->>API: Saga Step: Embedding
    API->>Qdrant: Upsert(points with doc_id filter)

    API->>API: Saga Step: Indexing
    API->>Neo4j: MERGE(Chunk nodes with doc_id)

    API->>SQLite: UpdateSagaStatus(Completed)
    API-->>User: 202 {document_id, status: processing}
```

**Compensation Logic (Implemented)**: If Neo4j insertion fails â†’ Qdrant DeleteDocument â†’ Saga Failed.

---

### 3.2 Retrieval & Generation Pipeline (Target State)

```mermaid
sequenceDiagram
    participant User
    participant API as Go API
    participant LLM as LLM Router
    participant Qdrant
    participant Neo4j
    participant Gemini

    User->>API: POST /api/v1/query {query}

    rect rgb(60, 40, 40)
    Note over API: Dual-level Retrieval
    API->>LLM: RouteLLMTask("keyword_extraction")
    LLM-->>API: Sub-queries / Keywords
    end

    rect rgb(40, 40, 80)
    Note over API,Neo4j: Parallel Fusion Retrieval (errgroup)
    par Graph Engine
        API->>Neo4j: Cypher Query (entity relationships)
    and RAPTOR Engine
        API->>Qdrant: Search(raptor_collection, summary vectors)
    and ColBERT Engine
        API->>Qdrant: Search(colbert_collection, token vectors)
    end
    Neo4j-->>API: Graph results
    Qdrant-->>API: RAPTOR results
    Qdrant-->>API: ColBERT results
    end

    API->>API: Intent Classification â†’ Skyline Ranker (Pareto)

    rect rgb(40, 60, 40)
    Note over API: Self-RAG Loop
    API->>LLM: "Is context relevant?" (Retrieval Critique)
    LLM-->>API: [Relevant] / [Irrelevant]
    API->>Gemini: Generate answer with context
    Gemini-->>API: Answer
    API->>LLM: "Is answer factually supported?" (Generation Critique)
    LLM-->>API: [Fully Supported] / [No Support]
    end

    API-->>User: SSE stream {reasoning, sources, answer}
```

---

## 4. Database & Index Responsibilities

### Qdrant (Vector DB)

| Collection | Purpose | Vector Type | Payload |
|---|---|---|---|
| `booksage_dense` | Dense Semantic Search | `Float32[768]` | `doc_id`, `chunk_id`, `text`, `page_number` |
| `booksage_colbert` | ColBERT Late Interaction | `MultiVector[seq_len Ã— 128]` | `doc_id`, `chunk_id`, `text` |
| `booksage_raptor` | RAPTOR Summary Tree | `Float32[768]` | `doc_id`, `level` (leaf/branch/root), `summary_text` |

**Filtering Strategy**: `doc_id` is set as a Payload Index across all collections. All searches use a `must` filter to scope requests to specific documents when necessary.

### Neo4j (Graph DB)

```
(:Document {doc_id, title, author})
    -[:HAS_CHAPTER]->
(:Chapter {chapter_number, title, doc_id})
    -[:HAS_CHUNK]->
(:Chunk {chunk_id, text, page_number, doc_id})

(:Entity {name, type})
    -[:MENTIONED_IN]->
(:Chunk)

(:Chunk)-[:NEXT_CHUNK]->(:Chunk)
```

| Node | Responsibility | Major Properties |
|---|---|---|
| Document | Book Metadata | `doc_id`, `title`, `author` |
| Chapter | TOC Structure (Two-Level Index) | `chapter_number`, `title` |
| Chunk | Text Fragment | `chunk_id`, `text`, `page_number` |
| Entity | NER Extracted Entities | `name`, `type` |

**Linking**: The `chunk_id` serves as the common key to join Qdrant payloads with Neo4j Chunk nodes.

---

## 5. Potential Technical Risks & Mitigations

| # | Risk | Impact | Mitigation |
|---|---|---|---|
| 1 | **gRPC Memory Spikes on Large PDFs** | Worker OOM Kill | Client Streaming chunk size restricted to `256KB` ã«åˆ¶é™ã€‚Workerå´ã§ `tempfile` ã«æ›¸ãå‡ºã—ã¦ã‹ã‚‰ãƒ‘ãƒ¼ã‚¹ (âœ… implemented) |
| 2 | **gRPC Timeouts** (Docling ETL can take minutes) | Parse RPC Failure | Sufficiently large `ParserTimeout` (currently 60s). Consider Bi-directional Streaming for progress updates in Phase 4. |
| 3 | **Embedding Batch Exceeding 4MB** | gRPC Resource Exhausted | Batcher (âœ… implemented, batch=100) splits messages into safe sizes. |
| 4 | **GPU CUDA Context Corruption** | Worker Freeze/Crash | `ProcessPoolExecutor` used for CPU tasks, `ThreadPoolExecutor` for GPU (âœ… Designed). |
| 5 | **Qdrant/Neo4j Data Inconsistency** | Mismatched Index States | Saga Compensation Pattern (âœ… implemented): Qdrant Rollback on Neo4j failure. |
| 6 | **Fusion Retrieval Latency** | Blocked by slowest engine | `errgroup` + `context.WithTimeout(3s)` + Fail-soft (âœ… Designed): Graceful degradation if one engine fails. |
| 7 | **ColBERT Storage Explosion** | Resource Exhaustion | Enabled Qdrant `Quantization` (Binary/Scalar). Use RAPTOR for summary compression of long documents. |
| 8 | **Cost Overruns on Cloud LLM** | Excessive Gemini Billing | `UseLocalOnlyLLM` flag (âœ… implemented): Use Ollama by default except for complex tasks. |
